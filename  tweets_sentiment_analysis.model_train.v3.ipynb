{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# <center>Model Training (v3)</center>", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "<br>\n<br>\n<p>First we run the previously developed code.</p>\n<br>\n<br>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "import pandas as pd\nfrom pyspark.sql import SparkSession\n\nspark = SparkSession.builder.appName('ml_tweet_sentiment').getOrCreate()\ndf = spark.read.csv('training_data.csv', header = True, inferSchema = True)\ndf.printSchema()\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "root\n |-- _c0: integer (nullable = true)\n |-- target: integer (nullable = true)\n |-- text: string (nullable = true)\n\n"
                }
            ], 
            "execution_count": 1
        }, 
        {
            "source": "ts = spark.read.csv('test_data.csv', header = True, inferSchema = True)\nts.printSchema()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "root\n |-- _c0: integer (nullable = true)\n |-- target: integer (nullable = true)\n |-- text: string (nullable = true)\n\n"
                }
            ], 
            "execution_count": 2
        }, 
        {
            "source": "df_train = df.select(df.target.alias(\"label\"), df.text)\ndf_train.show(5)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+-----+--------------------+\n|label|                text|\n+-----+--------------------+\n|    0|@switchfoot http:...|\n|    0|is upset that he ...|\n|    0|@Kenichan I dived...|\n|    0|my whole body fee...|\n|    0|@nationwideclass ...|\n+-----+--------------------+\nonly showing top 5 rows\n\n"
                }
            ], 
            "execution_count": 3
        }, 
        {
            "source": "df_test = ts.select(ts.target.alias(\"label\"), ts.text)\ndf_test.show(5)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+-----+--------------------+\n|label|                text|\n+-----+--------------------+\n|    1|@stellargirl I lo...|\n|    1|Reading my kindle...|\n|    1|Ok, first assesme...|\n|    1|@kenburbary You'l...|\n|    1|@mikefish  Fair e...|\n+-----+--------------------+\nonly showing top 5 rows\n\n"
                }
            ], 
            "execution_count": 4
        }, 
        {
            "source": "from pyspark.ml.feature import  Tokenizer, HashingTF, IDF\n\n\ntok = Tokenizer(inputCol=\"text\", outputCol=\"words\")\ntf = HashingTF(inputCol=\"words\", outputCol=\"tf\", numFeatures=500)\nidf = IDF(inputCol=\"tf\", outputCol=\"features\")\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 5
        }, 
        {
            "source": "#feat_pipeline = Pipeline(stages=[tok, tf, idf])\n\n#feat_model = feat_pipeline.fit(df)\n#features = feat_model.transform(df)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "#test_model = feat_pipeline.fit(ts)\n#test = test_model.transform(ts)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "<br>\n<br>\n<p>Now we'll train the model.</p>\n<br>\n<br>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "from pyspark.ml.classification import GBTClassifier\n\n\ngbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\", maxIter=10)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 6
        }, 
        {
            "source": "from pyspark.ml import Pipeline\n\n\npipeline = Pipeline(stages=[tok, tf, idf, gbt])", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 7
        }, 
        {
            "source": "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\nbinEval = MulticlassClassificationEvaluator().setMetricName(\"accuracy\") .setPredictionCol(\"prediction\").setLabelCol(\"label\")", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 8
        }, 
        {
            "source": "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n\n\nparamGrid = ParamGridBuilder() \\\n    .addGrid(tf.numFeatures, [50, 100]) \\\n    .addGrid(gbt.maxBins, [2,4]) \\\n    .addGrid(gbt.maxDepth, [2,4]) \\\n    .build()\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 9
        }, 
        {
            "source": "crossval = CrossValidator(estimator=pipeline,\n                          estimatorParamMaps=paramGrid,\n                          evaluator=MulticlassClassificationEvaluator(),\n                          numFolds=4)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 10
        }, 
        {
            "source": "model = crossval.fit(df_train)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 11
        }, 
        {
            "source": "prediction = model.transform(df_test)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 12
        }, 
        {
            "source": "binEval.evaluate(prediction)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "0.6100278551532033"
                    }, 
                    "execution_count": 13, 
                    "metadata": {}
                }
            ], 
            "execution_count": 13
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "pygments_lexer": "ipython3", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}